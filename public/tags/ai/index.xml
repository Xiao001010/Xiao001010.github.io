<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Hao Xu Blog</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in AI on Hao Xu Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Apr 2025 12:39:34 +0100</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Datawhale AI春训营SAIS Medicine</title>
      <link>http://localhost:1313/post/2025-04-13-sais-medicine/</link>
      <pubDate>Sun, 13 Apr 2025 12:39:34 +0100</pubDate>
      <guid>http://localhost:1313/post/2025-04-13-sais-medicine/</guid>
      <description>&lt;h1 id=&#34;improvements&#34;&gt;Improvements&lt;/h1&gt;&#xA;&lt;p&gt;相较于Datawhale 给出的 Baseline 代码，Task 2的代码有以下改进：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;更丰富的几何特征: 新代码引入了几何特征生成器，提供了 RBF（径向基函数）特征、二面角（dihedrals）和方向特征（direction feature）的计算。这使得节点特征不再局限于单纯的展平坐标，而是融合了局部几何信息，为模型提供更多结构化信息。&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Miscellaneous</title>
      <link>http://localhost:1313/post/2025-01-21-llm-miscellaneous/</link>
      <pubDate>Tue, 21 Jan 2025 14:23:16 +0000</pubDate>
      <guid>http://localhost:1313/post/2025-01-21-llm-miscellaneous/</guid>
      <description>&lt;h1 id=&#34;llm显存占用计算&#34;&gt;LLM显存占用计算&lt;/h1&gt;&#xA;&lt;h2 id=&#34;精度&#34;&gt;精度&lt;/h2&gt;&#xA;&lt;p&gt;FP32 (32 位浮点数): 32 bits = 4 bytes。标准精度，每个参数占用 4 字节。&#xA;FP16 (16 位浮点数): 16 bits = 2 bytes。半精度浮点数，每个参数占用 2 字节。&#xA;BP16 (16 位脑浮点数): 16 bits = 2 bytes。与 FP16 类似，但具有更大的指数范围，适用于深度学习。&#xA;INT8 (8 位整数): 8 bits = 1 byte。低精度整数精度，每个参数占用 1 字节。&#xA;量化 (4 位整数): 4 bits = 0.5 bytes。每个参数占用 0.5 字节。或者更低的精度，如 2 位整数。&lt;/p&gt;</description>
    </item>
    <item>
      <title>U-Net</title>
      <link>http://localhost:1313/post/2025-01-04-u-net/</link>
      <pubDate>Sat, 04 Jan 2025 21:59:30 +0000</pubDate>
      <guid>http://localhost:1313/post/2025-01-04-u-net/</guid>
      <description>&lt;h1 id=&#34;u-net复现&#34;&gt;U-Net复现&lt;/h1&gt;&#xA;&lt;p&gt;本篇内容是通过PyTorch来复现U-Net.&lt;/p&gt;&#xA;&lt;h1 id=&#34;模型总览&#34;&gt;模型总览&lt;/h1&gt;&#xA;&lt;p&gt;&#xA;  &lt;img src=&#34;http://localhost:1313/img/2025-01-04-U-Net/Untitled.png&#34; alt=&#34;Source U-Net&#34;&gt;&#xA;&#xA;&lt;/p&gt;&#xA;&lt;p&gt;Source &lt;a href=&#34;https://arxiv.org/abs/1505.04597&#34;&gt;U-Net&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;如上图（蓝色方块上方显示的是通道数，左下角显示的是数据的高宽）所示，U-Net 的模型结构符合我们前面说的 &lt;strong&gt;编码器/解码器结构 (Encoder/Decoder structure)&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Image Segmentation Basic Methods</title>
      <link>http://localhost:1313/post/2025-01-04-image-segmentation-basic-methods/</link>
      <pubDate>Sat, 04 Jan 2025 17:26:33 +0000</pubDate>
      <guid>http://localhost:1313/post/2025-01-04-image-segmentation-basic-methods/</guid>
      <description>&lt;h1 id=&#34;图像分割基本方法&#34;&gt;图像分割基本方法&lt;/h1&gt;&#xA;&lt;h1 id=&#34;输入输出&#34;&gt;输入输出&lt;/h1&gt;&#xA;&lt;p&gt;下面讲解一下模型的输入与输出的形式。尤其是输出。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;输入 (Input)&lt;/strong&gt;：RGB图像 (height, width, 3) 或者灰度图 (height, width, 1) 。第三个维度是通道数，RGB图像有三个通道，而灰度图只有一个通道。在第一维再加一个batch size 就是 RGB 图像 (batch_size, height, width, 3) / 灰度图 (batch_size, height, width, 1)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Image Segmentation Basic Concepts</title>
      <link>http://localhost:1313/post/2025-01-04-image-segmentation-basic-concepts/</link>
      <pubDate>Sat, 04 Jan 2025 16:36:37 +0000</pubDate>
      <guid>http://localhost:1313/post/2025-01-04-image-segmentation-basic-concepts/</guid>
      <description>&lt;h1 id=&#34;前言&#34;&gt;前言&lt;/h1&gt;&#xA;&lt;p&gt;人类对计算机视觉感兴趣的最重要的问题是&lt;strong&gt;图像分类 (Image Classification)、目标检测 (Object Detection) 和图像分割 (Image Segmentation)&lt;/strong&gt;，同时它们的难度也是依次递增。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
